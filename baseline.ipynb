{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69182db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from livelossplot import PlotLosses\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from tqdm import tqdm \n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# - try improve results\n",
    "# - save model\n",
    "# - add validation with livelossplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/Ferguson_fire_train.npy'\n",
    "val_path = 'data/Ferguson_fire_test.npy'\n",
    "test_path = 'data/Ferguson_fire_obs.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a61efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(arr, chunk_size):\n",
    "    L = len(arr)\n",
    "    num_chunks = L // chunk_size\n",
    "    remainder = L % chunk_size\n",
    "    chunks = np.split(arr[:L-remainder], num_chunks)\n",
    "    if remainder != 0:\n",
    "        chunks.append(arr[L-remainder:])\n",
    "    return chunks\n",
    "\n",
    "def create_x_y(data,chunk_size):\n",
    "    x = chunk(data,chunk_size)\n",
    "    y = chunk(data,chunk_size)\n",
    "    for i in range(len(x)):\n",
    "        x[i] = x[i][:-1]\n",
    "        y[i] = y[i][1:]\n",
    "    return np.concatenate(x),np.concatenate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c37cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "\n",
    "train_path = 'data/Ferguson_fire_train.npy'\n",
    "val_path = 'data/Ferguson_fire_test.npy'\n",
    "test_path = 'data/Ferguson_fire_obs.npy'\n",
    "\n",
    "train_data = np.array(np.load(open(train_path,'rb')))\n",
    "train_data_x, train_data_y = create_x_y(train_data, 100)\n",
    "tensor_x = torch.Tensor(train_data_x)\n",
    "tensor_y = torch.Tensor(train_data_y)\n",
    "train_dataset = TensorDataset(tensor_x,tensor_y)\n",
    "\n",
    "val_data = np.array(np.load(open(val_path,'rb')))\n",
    "val_data_x, val_data_y = create_x_y(val_data, 100)\n",
    "tensor_x = torch.Tensor(val_data_x)\n",
    "tensor_y = torch.Tensor(val_data_y)\n",
    "val_dataset = TensorDataset(tensor_x,tensor_y)\n",
    "\n",
    "test_data = np.array(np.load(open(test_path,'rb')))\n",
    "test_data_1D = np.reshape(test_data, (np.shape(test_data)[0],np.shape(test_data)[1]*np.shape(test_data)[2]))\n",
    "test_data_1D_shifted = torch.Tensor(test_data_1D[1:])\n",
    "test_data_1D = torch.Tensor(test_data_1D[:-1])\n",
    "test_dataset = TensorDataset(test_data_1D,test_data_1D_shifted)\n",
    "\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = data.DataLoader(dataset=val_dataset, batch_size=2*32, shuffle=False)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add4768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(autoencoder, train_data, val_data, kl_div_on=True, epochs=10, device='cpu', patience=3):\n",
    "    opt = torch.optim.Adam(autoencoder.parameters())\n",
    "    liveloss = PlotLosses()    \n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch+1} of {epochs}')\n",
    "        logs = {}\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        # Training\n",
    "        autoencoder.train()\n",
    "        print('Train:')\n",
    "        for batch, label in tqdm(train_data):\n",
    "            batch = batch.to(device)\n",
    "            batch = batch.reshape(batch.shape[0], 1, batch.shape[1], batch.shape[2])\n",
    "            opt.zero_grad()\n",
    "            x_hat, KL = autoencoder(batch)\n",
    "            loss = ((batch - x_hat) ** 2).sum() + KL\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_data)\n",
    "        logs['loss'] = train_loss\n",
    "        # Validation\n",
    "        autoencoder.eval()\n",
    "        print('Val:')\n",
    "        with torch.no_grad():\n",
    "            for batch, label in tqdm(val_data):\n",
    "                batch = batch.to(device)\n",
    "                batch = batch.reshape(batch.shape[0], 1, batch.shape[1], batch.shape[2])\n",
    "                x_hat, KL = autoencoder(batch)\n",
    "                loss = ((batch - x_hat) ** 2).sum() + KL\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_data)\n",
    "        logs['val_loss'] = val_loss\n",
    "        liveloss.update(logs)\n",
    "        liveloss.send()\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f\"Early stopping: No improvement in validation loss for {patience} epochs.\")\n",
    "                break\n",
    "    return autoencoder\n",
    "\n",
    "device = 'cpu'\n",
    "cvae = cVAE.VAE_Conv(device).to(device)\n",
    "cvae = train(cvae, train_loader, val_loader, epochs=30, device=device)\n",
    "torch.save(cvae.state_dict(), 'cvae.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e6ada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "cvae.eval()\n",
    "\n",
    "_, ax = plt.subplots(2, 5, figsize=[18.5, 6])\n",
    "for n, idx  in enumerate(torch.randint(0,images.shape[0], (5,))):\n",
    "    recon, _ = cvae(images[idx].unsqueeze(0)) \n",
    "    ax[0, n].imshow(labels[idx].squeeze())\n",
    "    ax[1, n].imshow(recon.cpu().detach().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75569e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mse between train and test here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09544f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results on obs data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e09fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mse between actual obs data and predicted obs data here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
