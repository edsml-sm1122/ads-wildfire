{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fef22102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from utils.train import create_dataloader, train\n",
    "from models import cVAE, cLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e915db84",
   "metadata": {},
   "source": [
    "### Load/Process Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83b5aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(TensorDataset):\n",
    "    def __init__(self, data,sequence_length=4):\n",
    "        self.data = data.astype('float64')\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        sample_input = torch.tensor(self.data[idx:idx+self.sequence_length])      \n",
    "        sample_output = torch.tensor(self.data[idx+1:idx+self.sequence_length+1])\n",
    "\n",
    "        return sample_input[:,None,:], sample_output[:,None,:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.sequence_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeddf6c4",
   "metadata": {},
   "source": [
    "Note: I'm training with sequence_length (i.e. window) = 1 which doesn't really make sense for an LSTM but I think it's what they want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6a25379",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/Ferguson_fire_train.npy'\n",
    "train_data = np.load(train_path)\n",
    "train_dataset = SequenceDataset(train_data, sequence_length=1)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "val_path = 'data/Ferguson_fire_test.npy'\n",
    "val_data = np.load(val_path)\n",
    "val_dataset = SequenceDataset(val_data, sequence_length=1)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f943b1",
   "metadata": {},
   "source": [
    "### Train (ConvLSTM) Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2098d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 20\n",
      "Train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/391 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1, 1, 256, 256])) that is different to the input size (torch.Size([32, 256, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      " 78%|███████████████████████████████▉         | 304/391 [12:03<03:27,  2.38s/it]"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "n_layers = 1\n",
    "\n",
    "sequence_length = 1\n",
    "channels = 1\n",
    "epochs = 20\n",
    "clstm = cLSTM.ConvLSTM(input_dim=channels,\n",
    "                 hidden_dim=16,\n",
    "                 kernel_size=(3, 3),\n",
    "                 num_layers=1,\n",
    "                 batch_first=True,\n",
    "                 bias=True,\n",
    "                 return_all_layers=False).to(device)\n",
    "\n",
    "if not os.path.exists('models/clstm.pt'):\n",
    "    clstm = train(clstm, train_loader, val_loader, epochs=epochs, device=device)\n",
    "    if not os.path.exists('models/'):\n",
    "        os.makedirs('models/')\n",
    "    torch.save(clstm.state_dict(), 'models/clstm.pt')\n",
    "else:\n",
    "    clstm.load_state_dict(torch.load('models/clstm.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5457284e",
   "metadata": {},
   "source": [
    "### Plot validation results (actual vs forecasted):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a3065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels = next(iter(train_loader))\n",
    "# cvae.eval()\n",
    "\n",
    "# fig, ax = plt.subplots(2, 5, figsize=[18.5, 6])\n",
    "# fig.tight_layout(pad=4)\n",
    "# for n, idx  in enumerate(torch.randint(0,images.shape[0], (5,))):\n",
    "#     recon, _ = cvae(images[idx].unsqueeze(0)) \n",
    "#     ax[0, n].imshow(labels[idx].squeeze())\n",
    "#     ax[0, n].axis('off')\n",
    "#     ax[1, n].imshow(recon.cpu().detach().squeeze())\n",
    "#     ax[1, n].axis('off')\n",
    "#     if n==0:\n",
    "#         ax[0,n].set_title('(Val) Actual:', fontsize=20, pad=20, loc='left')\n",
    "#         ax[1,n].set_title('(Val) Forecasted:', fontsize=20, pad=20, loc='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0bb304",
   "metadata": {},
   "source": [
    "### Plot test results (actual vs forecasted):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d5331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_path = 'data/Ferguson_fire_obs.npy'\n",
    "# test_data = np.array(np.load(open(test_path,'rb')))\n",
    "# test_data_shifted = torch.Tensor(test_data[1:])\n",
    "# test_data = torch.Tensor(test_data[:-1])\n",
    "# test_dataset = TensorDataset(test_data,test_data_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8df841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2, 4, figsize=[18.5, 6])\n",
    "# fig.tight_layout(pad=4)\n",
    "# mses = []\n",
    "# for n,(image,label) in enumerate(test_dataset):\n",
    "#     recon, _ = cvae(image.unsqueeze(0)) \n",
    "#     mses.append(mean_squared_error(label.flatten(),recon.cpu().detach().squeeze().flatten()))\n",
    "#     ax[0, n].axis('off')\n",
    "#     ax[0, n].imshow(label.squeeze())\n",
    "#     ax[1, n].imshow(recon.cpu().detach().squeeze())\n",
    "#     ax[1, n].axis('off')\n",
    "#     if n==0:\n",
    "#         ax[0,n].set_title('(Test) Actual:', fontsize=20, pad=20, loc='left')\n",
    "#         ax[1,n].set_title('(Test) Forecasted:', fontsize=20, pad=20, loc='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04756236",
   "metadata": {},
   "source": [
    "### MSE test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d49c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'(Test) MSE: {sum(mses)/len(test_dataset)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
